import json
import jsonpatch
import sys
import subprocess
import time
from typing import Any, Dict, List, Optional

from kubernetes import client, config
from kubernetes.client import V1Deployment, V1Pod
from kubernetes.client.rest import ApiException
from kubernetes.stream import stream

from .exceptions import K8sError
from .logger import SecurityLogger, setup_logger


class K8sClient:
    """Wrapper for Kubernetes client operations."""

    def __init__(
        self, namespace: str = "default", logger: Optional[SecurityLogger] = None, verbose: bool = False
    ):
        self.namespace = namespace
        self.logger = logger or SecurityLogger(setup_logger(__name__))
        self.verbose = verbose

        # Initialize Kubernetes client
        try:
            config.load_incluster_config()
        except config.ConfigException:
            try:
                config.load_kube_config()
            except config.ConfigException:
                raise K8sError("Cannot connect to Kubernetes cluster")

        self.v1 = client.CoreV1Api()
        self.apps_v1 = client.AppsV1Api()

    def get_deployment(self, name: str) -> Optional[V1Deployment]:
        """Get a deployment by name."""
        try:
            deployment = self.apps_v1.read_namespaced_deployment(name, self.namespace)
            return deployment # type: ignore[attr-defined]
        except ApiException as e:
            if e.status == 404:
                return None
            raise K8sError(f"Failed to get deployment {name}: {e}")

    def find_pod_for_service(self, service: str) -> Optional[str]:
        """Find running pod for a service."""
        strategies = [
            # Strategy 1: Label app.kubernetes.io/name
            {"app.kubernetes.io/name": service.replace("unguard-", "")},
            # Strategy 2: Label app
            {"app": service},
            {"app": service.replace("unguard-", "")},
            # Strategy 3: Other common patterns
            {"component": service.replace("unguard-", "")},
            {"service": service},
            {"name": service},
        ]

        for labels in strategies:
            pods = self._get_pods_by_labels(labels)
            if pods and len(pods) > 0:
                return pods[0].metadata.name # type: ignore[attr-defined]

        # Strategy 4: Name prefix
        try:
            all_pods = self.v1.list_namespaced_pod(self.namespace)
            for pod in all_pods.items:
                if (
                    pod.metadata.name.startswith(service)
                    and pod.status.phase == "Running"
                ):
                    return pod.metadata.name
        except ApiException:
            pass

        return None

    def _get_pods_by_labels(self, labels: Dict[str, str]) -> List[V1Pod]:
        """Get pods by label selector."""
        label_selector = ",".join(f"{k}={v}" for k, v in labels.items())
        try:
            pod_list = self.v1.list_namespaced_pod(
                self.namespace, label_selector=label_selector
            )
            return [p for p in pod_list.items if p.status.phase == "Running"]
        except ApiException:
            return []

    def exec_in_pod(
        self, pod_name: str, command: str, container: Optional[str] = None
    ) -> str:
        """Execute command in pod."""
        try:
            pod = self.v1.read_namespaced_pod(pod_name, self.namespace)
            container_names = [c.name for c in pod.spec.containers] # type: ignore[attr-defined]

            if not container and len(container_names) > 1:
                self.logger.warning(
                    "Multiple containers found. Using the first container by default."
                )

            exec_command = ["/bin/sh", "-c", command]
            kwargs = {
                "name": pod_name,
                "namespace": self.namespace,
                "command": exec_command,
                "stderr": True,
                "stdin": False,
                "stdout": True,
                "tty": False,
                "_preload_content": False,
            }

            if container:
                kwargs["container"] = container
            elif len(container_names) > 1:
                kwargs["container"] = container_names[0]

            resp = stream(self.v1.connect_get_namespaced_pod_exec, **kwargs)
            output = ""
            
            # Fix: Properly handle stream output
            while resp.is_open():
                resp.update(timeout=1)
                if resp.peek_stdout():
                    data = resp.read_stdout()
                    output += data
                    # Print output in real-time if verbose
                    if self.verbose:
                        print(data, end='')
                if resp.peek_stderr():
                    data = resp.read_stderr()
                    output += data
                    if self.verbose:
                        print(data, end='', file=sys.stderr)
                        
            resp.close()
            return output.strip()  # Fix: Strip trailing whitespace
        except ApiException as e:
            raise K8sError(f"Failed to exec in pod {pod_name}: {e}")

    def patch_deployment(
        self, name: str, patches: List[Dict[str, Any]], dry_run: bool = False
    ) -> bool:
        """Apply JSON patch to deployment with verbose logging."""
        try:
            # Get current deployment
            deployment = self.get_deployment(name)
            if not deployment:
                raise K8sError(f"Deployment {name} not found")

            # Convert to dict
            deployment_dict = client.ApiClient().sanitize_for_serialization(deployment)

            # Log current state if verbose
            if self.verbose:
                self.logger.info(f"Current deployment state for {name}:")
                self._log_deployment_security_context(deployment_dict) # type: ignore[attr-defined]

            # Log patches being applied
            if self.verbose or dry_run:
                self.logger.info(f"Patches to be applied to {name}:")
                for patch in patches:
                    self.logger.info(f"  {json.dumps(patch, indent=2)}")

            # Apply patches
            try:
                patched = jsonpatch.apply_patch(deployment_dict, patches)
            except jsonpatch.JsonPatchException as e:
                self.logger.error(f"Patch validation failed: {e}")
                return False

            # Log patched state if verbose
            if self.verbose:
                self.logger.info(f"Patched deployment state for {name}:")
                self._log_deployment_security_context(patched)

            # Apply to cluster
            if not dry_run:
                self.apps_v1.patch_namespaced_deployment(
                    name=name, namespace=self.namespace, body=patched
                )
                self.logger.success(f"Patched {name}")

                # Wait for rollout
                self.wait_for_rollout(name)
            else:
                self.logger.info(f"DRY RUN: Would patch {name}")

            return True

        except ApiException as e:
            self.logger.error(f"Failed to patch {name}: {e}")
            return False

    def _log_deployment_security_context(self, deployment_dict: Dict[str, Any]) -> None:
        """Log security-relevant parts of deployment."""
        try:
            spec = deployment_dict.get("spec", {}).get("template", {}).get("spec", {})
            
            # Log pod-level security settings
            self.logger.info("  Pod-level security:")
            self.logger.info(f"    hostPID: {spec.get('hostPID', False)}")
            self.logger.info(f"    hostNetwork: {spec.get('hostNetwork', False)}")
            self.logger.info(f"    hostIPC: {spec.get('hostIPC', False)}")
            
            # Log container security contexts
            containers = spec.get("containers", [])
            for i, container in enumerate(containers):
                self.logger.info(f"  Container {i} ({container.get('name', 'unnamed')}):")
                sec_ctx = container.get("securityContext", {})
                if sec_ctx:
                    self.logger.info(f"    privileged: {sec_ctx.get('privileged', False)}")
                    self.logger.info(f"    runAsNonRoot: {sec_ctx.get('runAsNonRoot', 'not set')}")
                    self.logger.info(f"    runAsUser: {sec_ctx.get('runAsUser', 'not set')}")
                    self.logger.info(f"    allowPrivilegeEscalation: {sec_ctx.get('allowPrivilegeEscalation', 'not set')}")
                    caps = sec_ctx.get('capabilities', {})
                    if caps:
                        self.logger.info(f"    capabilities.add: {caps.get('add', [])}")
                        self.logger.info(f"    capabilities.drop: {caps.get('drop', [])}")
                else:
                    self.logger.info("    No security context defined")
                
                # Log resource limits
                resources = container.get("resources", {})
                if resources:
                    limits = resources.get("limits", {})
                    requests = resources.get("requests", {})
                    self.logger.info(f"    resources.limits: {limits}")
                    self.logger.info(f"    resources.requests: {requests}")
                else:
                    self.logger.info("    No resource limits defined")
        except Exception as e:
            self.logger.error(f"Error logging deployment state: {e}")

    def wait_for_rollout(self, deployment_name: str, timeout: int = 120) -> bool:
        """Wait for deployment rollout to complete."""
        self.logger.info(f"Waiting for {deployment_name} rollout...")
        start_time = time.time()

        while time.time() - start_time < timeout:
            deployment = self.get_deployment(deployment_name)
            if not deployment:
                return False

            # Check if rollout is complete - handle None values
            if deployment.status:
                updated = deployment.status.updated_replicas or 0
                ready = deployment.status.ready_replicas or 0
            else:
                updated = 0
                ready = 0

            replicas = deployment.spec.replicas or 0 # type: ignore[attr-defined]

            if updated == replicas and ready == replicas and replicas > 0:
                self.logger.success(f"{deployment_name} rollout complete")
                return True

            time.sleep(5)

        self.logger.warning(f"Timeout waiting for {deployment_name} rollout")
        return False

    def rollback_deployment(self, name: str, revision: Optional[int] = None) -> bool:
        """Rollback deployment to previous or specific revision."""
        try:
            cmd = [
                "kubectl",
                "rollout",
                "undo",
                f"deployment/{name}",
                "-n",
                self.namespace,
            ]
            if revision:
                cmd.extend(["--to-revision", str(revision)])
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                self.logger.success(
                    f"Rolled back {name} to revision {revision or 'previous'}."
                )
                return True
            else:
                self.logger.error(f"Failed to rollback {name}: {result.stderr}")
                return False
        except Exception as e:
            self.logger.error(f"Error during rollback: {e}")
            return False

    def deployment_exists(self, name: str, namespace: Optional[str] = None) -> bool:
            """Check if a deployment exists in the specified namespace."""
            ns = namespace or self.namespace
            try:
                self.apps_v1.read_namespaced_deployment(name, ns)
                return True
            except ApiException as e:
                if e.status == 404:
                    return False
                raise K8sError(f"Failed to check deployment {name}: {e}")

    def delete_deployment(self, name: str, namespace: Optional[str] = None) -> bool:
        """Delete a deployment."""
        ns = namespace or self.namespace
        try:
            self.apps_v1.delete_namespaced_deployment(
                name=name,
                namespace=ns,
                body=client.V1DeleteOptions()
            )
            self.logger.success(f"Deleted deployment {name}")
            return True
        except ApiException as e:
            if e.status == 404:
                self.logger.warning(f"Deployment {name} not found")
                return False
            self.logger.error(f"Failed to delete deployment {name}: {e}")
            return False

    def namespace_exists(self, name: str) -> bool:
        """Check if a namespace exists."""
        try:
            self.v1.read_namespace(name)
            return True
        except ApiException as e:
            if e.status == 404:
                return False
            raise K8sError(f"Failed to check namespace {name}: {e}")